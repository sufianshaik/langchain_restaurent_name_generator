{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2/yW9ICjUNpdRHQSrGgvm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sufianshaik/langchain_restaurent_name_generator/blob/main/LangChain_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "msjBdGwYp6ua"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "# store the value as the dictionary pair and key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUpHDt-VeqEu",
        "outputId": "29fa562e-ab9f-44fa-921c-39da6e9bfa3a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.10-py3-none-any.whl (806 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.2/806.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.25 (from langchain)\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.28 (from langchain)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain)\n",
            "  Downloading langsmith-0.1.13-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.28->langchain) (23.2)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.10 langchain-community-0.0.25 langchain-core-0.1.28 langchain-text-splitters-0.0.1 langsmith-0.1.13 marshmallow-3.21.0 mypy-extensions-1.0.0 orjson-3.9.15 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 openai-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "llm = OpenAI(temperature=0.6)\n",
        "# temperature is the creative type for a model which we give 0 indicates the safe search where as close to 1 may result in some irrelevent answers\n",
        "name = llm(\"I want to open a restaurent for italian food.Can you suggest any fancy name for this.\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90gfnrrgq0fn",
        "outputId": "56a094af-57ec-438f-ca71-5bc6a9658214"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. \"Bella Cucina\"\n",
            "2. \"Ciao Bella\"\n",
            "3. \"La Dolce Vita\"\n",
            "4. \"Amore Italiano\"\n",
            "5. \"Fresco Ristorante\"\n",
            "6. \"Mamma Mia's Trattoria\"\n",
            "7. \"Bistecca e Vino\"\n",
            "8. \"Buon Appetito\"\n",
            "9. \"Grazie Trattoria\"\n",
            "10. \"Fiori di Zucca Ristorante\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt template is used to create a template which can be used via a format or using a chain later stage to send the prompt\n",
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables=[\"cuisine\"],\n",
        "    template= \"I want to open a restaurent for {cuisine} food.Can you suggest any fancy name for this.\"\n",
        ")"
      ],
      "metadata": {
        "id": "3xktg7bKs20j"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  LLMChain is takes the llm type and the promptTemplate which can be later used to run the chain providing the only name in the .run method like below\n",
        "from langchain.chains import LLMChain\n",
        "chain = LLMChain(llm= llm, prompt=prompt_template_name);\n",
        "chain.run(\"American\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "CAUSovHEW2Z2",
        "outputId": "f64f40ae-b03d-4f0c-b38f-c604d1ffca3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n1. Stateside Bites\\n2. Yankee's Kitchen\\n3. The American Table \\n4. Uncle Sam's Diner \\n5. Liberty's Kitchen \\n6. Stars and Stripes Grill \\n7. Red, White & Blue Bistro \\n8. All-American Eats \\n9. Americana Kitchen & Bar \\n10. The Patriot's Pantry \\n11. The Great American Diner \\n12. USA Fare \\n13. The American Dream Cafe \\n14. Freedom's Flavors \\n15. The American Plate \\n16. The Founding Fathers' Feast \\n17. The American Palate \\n18. Americana Bistro \\n19. Yankee Doodle Diner \\n20. The American Farewell.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple Sequential Steps :\n",
        "* this is like a chain which takes the steps of input where except for the 1st time the input for 2nd is the output from the 1st chain such that\n",
        "* input = \"indian\" ---> Generate Restaurent Name ---> restraurentNAme = \"Tandoor Bites\" ---> Give me food menu items --> Output = paneer, samosa, dosa etc\n",
        "* simple sequtntial chain has only one input and one output\n"
      ],
      "metadata": {
        "id": "aHIxqk5zfyhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simpleSequentialChain which only gives the input and output once\n",
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template_resName = PromptTemplate(\n",
        "    input_variables=[\"cuisine\"],\n",
        "    template= \"I want to open a restaurent for {cuisine} food.Can you suggest any fancy name for this.\"\n",
        ")\n",
        "\n",
        "name_chain = LLMChain(llm = llm, prompt =prompt_template_resName)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables=[\"restaurant_name\"],\n",
        "    template= \"What are the items present at {restaurant_name}, return as comma seperated list\"\n",
        ")\n",
        "item_chain = LLMChain(llm = llm, prompt = prompt_template_items)\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain( chains= [name_chain, item_chain] )\n",
        "print(chain.run(\"Indian\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ium2OzWlgeZQ",
        "outputId": "80174cae-1e59-4ae7-c73e-cfd738f9042b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. \"Taste of India\" - Samosas, Butter Chicken, Chicken Tikka Masala, Naan, Vegetable Biryani, Mango Lassi\n",
            "2. \"Spice Route\" - Lamb Vindaloo, Chicken Korma, Palak Paneer, Garlic Naan, Mango Chutney, Masala Chai\n",
            "3. \"Saffron Palace\" - Tandoori Chicken, Lamb Biryani, Saag Aloo, Roti, Raita, Gulab Jamun\n",
            "4. \"Curry Kingdom\" - Chicken Curry, Beef Madras, Aloo Gobi, Paratha, Mango Lassi, Kulfi\n",
            "5. \"Masala Magic\" - Butter Chicken, Lamb Rogan Josh, Chana Masala, Garlic Naan, Mango Lassi, Kheer\n",
            "6. \"Naan Stop\" - Chicken Tikka Masala, Vegetable Biryani, Saag Paneer, Naan, Mango Lassi, Ras Malai\n",
            "7. \"Flavors of the East\" - Chicken Tandoori, Fish Curry, Dal Makhani, Roti, Mango Chutney, Masala Chai\n",
            "8. \"Tandoori Tales\" - Lamb Tikka, Chicken\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SequentialChain gives the input and output of the intermediatery chains also\n",
        "# in additional to simpleSequentialChain while creating the promptTemplate in the sequentialChain we should make sure to add the output_key\n",
        "from langchain.prompts import PromptTemplate\n",
        "prompt_template_resName = PromptTemplate(\n",
        "    input_variables=[\"cuisine\"],\n",
        "    template= \"I want to open a restaurent for {cuisine} food.Can you suggest any fancy name for this.\"\n",
        ")\n",
        "# creating the 1st chain with the input of cuisine and output as restaurant_name from here below\n",
        "name_chain = LLMChain(llm = llm, prompt = prompt_template_resName, output_key = \"restaurant_name\")\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables=[\"restaurant_name\"],\n",
        "    template= \"What are the items present at {restaurant_name}, return as comma seperated list\"\n",
        ")\n",
        "# creating the 2nd chain with the input of the 1st chain i.e restaurant_name and output as items which is as below\n",
        "item_chain = LLMChain(llm = llm, prompt = prompt_template_items, output_key = \"items\")\n",
        "\n",
        "\n",
        "# combining the both chains to sequentialchain to perform operations on the final to obtain desired inputs and outputs\n",
        "from langchain.chains import SequentialChain\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, item_chain],\n",
        "    input_variables = ['cuisine'],\n",
        "    output_variables = ['restaurant_name' , 'items']\n",
        ")\n",
        "\n",
        "chain({'cuisine' : \"indian\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_6kwEo2hlOT",
        "outputId": "9de2a8cb-c91a-4713-8953-ad92cf78496b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'indian',\n",
              " 'restaurant_name': '\\n\\n1. \"Taste of India\"\\n2. \"Spice Fusion\"\\n3. \"Curry Delight\"\\n4. \"Saffron Bistro\"\\n5. \"Masala Magic\"\\n6. \"Flavors of the East\"\\n7. \"The Tandoori Oven\"\\n8. \"Naan Stop\"\\n9. \"Chai and Chaat\"\\n10. \"Bollywood Bites\"',\n",
              " 'items': '\\n\\n1. \"Taste of India\" - Samosas, tandoori chicken, butter chicken, naan bread, biryani, mango lassi\\n2. \"Spice Fusion\" - Chicken tikka masala, lamb vindaloo, vegetable korma, garlic naan, mango chutney, chai tea\\n3. \"Curry Delight\" - Chicken curry, palak paneer, aloo gobi, basmati rice, garlic naan, mango lassi\\n4. \"Saffron Bistro\" - Lamb rogan josh, chicken biryani, saffron rice, garlic naan, mango lassi, chai tea\\n5. \"Masala Magic\" - Butter chicken, vegetable samosas, chana masala, garlic naan, mango lassi, masala chai\\n6. \"Flavors of the East\" - Tandoori chicken, shrimp biryani, vegetable biryani, garlic naan, mango lassi, chai tea\\n7. \"The Tandoori Oven\" - Chicken tikka, lamb kebab, tandoori shrimp, naan bread, basmati rice, mango lassi\\n8. \"Naan Stop\" - Chicken tikka'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain aganets\n",
        "\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.6)\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm = llm)\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    # reasoning thought and action\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    # verbose is the tool which shows all the internal steps in detail in any of the method or body\n",
        "    verbose = True\n",
        ")\n",
        "\n",
        "agent.run(\"When was Elon musk born? what is his age right now in 2024?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "IZLMuYfxtFop",
        "outputId": "c1b4e176-21e2-4a1f-85c8-7521f040a2c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use wikipedia to find information about Elon Musk's birthdate and age.\n",
            "Action: wikipedia\n",
            "Action Input: \"Elon Musk\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPage: Elon Musk\n",
            "Summary: Elon Reeve Musk (; EE-lon; born June 28, 1971) is a businessman and investor. He is the founder, chairman, CEO, and CTO of SpaceX; angel investor, CEO, product architect, and former chairman of Tesla, Inc.; owner, executive chairman, and CTO of X Corp.; founder of the Boring Company and xAI; co-founder of Neuralink and OpenAI; and president of the Musk Foundation. He is one of the wealthiest people in the world, with an estimated net worth of US$213 billion as of February 2024, according to the Bloomberg Billionaires Index, and $210 billion according to Forbes, primarily from his ownership stakes in Tesla and SpaceX.A member of the wealthy South African Musk family, Elon was born in Pretoria and briefly attended the University of Pretoria before immigrating to Canada at age 18, acquiring citizenship through his Canadian-born mother. Two years later, he matriculated at Queen's University at Kingston in Canada. Musk later transferred to the University of Pennsylvania, and received bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University, but dropped out after two days and, with his brother Kimbal, co-founded online city guide software company Zip2. The startup was acquired by Compaq for $307 million in 1999, and that same year Musk co-founded X.com, a direct bank. X.com merged with Confinity in 2000 to form PayPal.\n",
            "In October 2002, eBay acquired PayPal for $1.5 billion, and that same year, with $100 million of the money he made, Musk founded SpaceX, a spaceflight services company. In 2004, he became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (now Tesla, Inc.). He became its chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2022, he acquired Twitter for $44 billion. He subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, he founded xAI, an artificial intelligence company.\n",
            "Musk has expressed views that have made him a polarizing figure. He has been criticized for making unscientific and misleading statements, including COVID-19 misinformation and antisemitic conspiracy theories. His ownership of Twitter has been similarly controversial, being marked by the laying off of a large number of employees, an increase in hate speech and misinformation and disinformation on the website, as well as changes to Twitter Blue verification. In 2018, the U.S. Securities and Exchange Commission (SEC) sued him, alleging that he had falsely announced that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine.\n",
            "\n",
            "Page: Twitter under Elon Musk\n",
            "Summary: Elon Musk completed his acquisition of Twitter in October 2022; Musk acted as CEO of Twitter until June 2023 when he was succeeded by Linda Yaccarino. Twitter was then rebranded to X in July 2023. Initially during Musk's tenure, Twitter introduced a series of reforms and management changes; the company reinstated a number of previously banned accounts, reduced the workforce by approximately 80%, closed one of Twitter's three data centers, and largely eliminated the content moderation team, replacing it with the crowd-sourced fact-checking system Community Notes.\n",
            "In November 2022, Twitter then began offering paid verification checkmarks, followed by removing legacy verification. In December, the Twitter Files were released and a number of journalists suspended from the platform. The f\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use the information from the wikipedia page about Elon Musk to calculate his age in 2024.\n",
            "Action: Calculator\n",
            "Action Input: \"2024 - 1971\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 53\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: 53 years old\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'53 years old'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgMv-E8T0Pog",
        "outputId": "2a7c8ebc-c3db-473d-c28f-def40d84f59b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11678 sha256=0aa13744409d8727b342f21bd97dab30a0631377f562cff84786099462eeadfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SERPAPI_API_KEY\"] = \"41f04dcea6040a4890fa26bf0a3c189c39e6c07638fac2552134e3f896f66ac2\"\n"
      ],
      "metadata": {
        "id": "twGlxd9B2Oxw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature = 0.6)\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm = llm)\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = True\n",
        ")\n",
        "agent.run(\"What was the GDP of US in 2022 plus 5 ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "hpLEW5hF2YFX",
        "outputId": "c3786281-f7fb-4a0a-d51a-53f602098f80"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should search for the answer using a search engine.\n",
            "Action: Search\n",
            "Action Input: \"GDP of US in 2022\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m$25.46 trillion\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use a calculator to add 5 to the GDP.\n",
            "Action: Calculator\n",
            "Action Input: 25.46 trillion + 5\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 25460000000005.0\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The GDP of US in 2022 plus 5 is $25.46 trillion + 5 = $25.46 trillion.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The GDP of US in 2022 plus 5 is $25.46 trillion + 5 = $25.46 trillion.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wv4w36327q2",
        "outputId": "7047dd44-e9b6-42f1-ff8d-790a61d9fabc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=d1de5769dd3da0aa72032f87509d04860ae67c81e25cabf2d1ad72ce201df268\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can create the memory for the chain which is by default NoneType\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "# prompt_template_name = PromptTemplate(\n",
        "#     input_variables=[\"cuisine\"],\n",
        "#     template= \"I want to open a restaurent for {cuisine} food.Can you suggest any fancy name for this.\"\n",
        "# )\n",
        "chain = LLMChain(llm = llm, prompt = prompt_template_name, memory = memory)\n",
        "name = chain.run(\"Mexico\")\n",
        "print(name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0rxo7yS4YQc",
        "outputId": "31505ae6-bf0f-4cdf-99da-14de5f16e966"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. \"Casa de Mexico\"\n",
            "2. \"Fiesta Mexicana\"\n",
            "3. \"El Sabor Mexicano\"\n",
            "4. \"La Cocina Mexicana\"\n",
            "5. \"Taco Loco\"\n",
            "6. \"Cantina del Sol\"\n",
            "7. \"Enchilada Express\"\n",
            "8. \"Taqueria del Mar\"\n",
            "9. \"El Ranchero\"\n",
            "10. \"Salsa y Tequila\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "name = chain.run(\"Chinese\")\n",
        "print(name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIGCmCsj47Sc",
        "outputId": "11ad37d5-8be4-46dd-958c-0eb850518f9c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Dragon's Den\n",
            "2. Oriental Palace\n",
            "3. China Garden\n",
            "4. Red Lantern\n",
            "5. Golden Chopsticks\n",
            "6. Jade Palace\n",
            "7. Dynasty Bistro\n",
            "8. The Great Wall\n",
            "9. East Meets West\n",
            "10. Wok & Roll\n",
            "11. Forbidden City\n",
            "12. Shanghai Nights\n",
            "13. Lucky Panda\n",
            "14. Ming Court\n",
            "15. The Silk Road\n",
            "16. Imperial Kitchen\n",
            "17. Chopstick House\n",
            "18. Bamboo Garden\n",
            "19. Szechuan Garden\n",
            "20. Dragonfly Dining\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we can find in much detail\n",
        "print(chain.memory.buffer)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cihicHAI5Dhu",
        "outputId": "3d4f7bbe-3d3c-4143-89a1-ec3abe4a73d6"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexico\n",
            "AI: \n",
            "\n",
            "1. \"Casa de Mexico\"\n",
            "2. \"Fiesta Mexicana\"\n",
            "3. \"El Sabor Mexicano\"\n",
            "4. \"La Cocina Mexicana\"\n",
            "5. \"Taco Loco\"\n",
            "6. \"Cantina del Sol\"\n",
            "7. \"Enchilada Express\"\n",
            "8. \"Taqueria del Mar\"\n",
            "9. \"El Ranchero\"\n",
            "10. \"Salsa y Tequila\"\n",
            "Human: Chinese\n",
            "AI: \n",
            "\n",
            "1. Dragon's Den\n",
            "2. Oriental Palace\n",
            "3. China Garden\n",
            "4. Red Lantern\n",
            "5. Golden Chopsticks\n",
            "6. Jade Palace\n",
            "7. Dynasty Bistro\n",
            "8. The Great Wall\n",
            "9. East Meets West\n",
            "10. Wok & Roll\n",
            "11. Forbidden City\n",
            "12. Shanghai Nights\n",
            "13. Lucky Panda\n",
            "14. Ming Court\n",
            "15. The Silk Road\n",
            "16. Imperial Kitchen\n",
            "17. Chopstick House\n",
            "18. Bamboo Garden\n",
            "19. Szechuan Garden\n",
            "20. Dragonfly Dining\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "convo = ConversationChain(llm = OpenAI(temperature = 0.7))\n",
        "print(convo.prompt.template)\n",
        "# when we click on the convo.run and check buffer printing we can see"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40OteiXf5DZl",
        "outputId": "4e53b8b8-e8da-4365-8ecf-d863f4186867"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# only limiting the memory to certain window\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "memory = ConversationBufferWindowMemory(k = 1)\n",
        "convo = ConversationChain(\n",
        "    llm = OpenAI(temperature=0.7),\n",
        "    memory = memory\n",
        ")"
      ],
      "metadata": {
        "id": "x3dUXnuo6V8o"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"who won the first cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "CvFZWOjD6-gl",
        "outputId": "68578fd4-a86b-452e-c1ae-b35d59970bf5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first Cricket World Cup was held in 1975 and was won by the West Indies team. The final match was played between the West Indies and Australia, with the West Indies winning by 17 runs. The captain of the West Indies team at the time was Clive Lloyd.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"5 + 5 =? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "6_Tcac-s7AkO",
        "outputId": "025e78c9-82b4-4105-d6b7-e5e613fca041"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 5 + 5 = 10. Is there anything else you would like to know?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convo.run(\"who was the captain of the winning team?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "12Ddr_1F7D0k",
        "outputId": "209c66c6-1670-41ca-cddc-3dc0da857ef8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I do not have enough context to accurately answer that question. Do you have any other questions?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    }
  ]
}